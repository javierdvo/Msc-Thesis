\babel@toc {english}{}
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {2.1}{\ignorespaces {\bf Some types of nucleotide mutations\cite {muts}} This shows the three most common variations. The SNP is on the left, then an insertion where a sequence is inserted, and the deletion where the opposite occurs}}{13}{figure.2.1}% 
\contentsline {figure}{\numberline {2.2}{\ignorespaces {\bf Example of LD plots of marker rs17848945 \cite {ldfig}} Image a) gives the LD plot of the given SNP and the $R^2$ value of close SNPs. Image b) shows the LD block plot for further correlation analysis}}{15}{figure.2.2}% 
\contentsline {figure}{\numberline {2.3}{\ignorespaces {\bf Calculated Polygenic component of Schizophrenia and Bipolar disorder, as well as non-psychiatric\cite {Consortium2009}} Calculated $R^2$ for Schizophrenia, Bipolar Disorder using different SNP thresholds. On the right are some common diseases. CAD, coronary artery disease; CD, Crohn\IeC {\textquoteright }s disease; HT, hypertension; RA, rheumatoid arthritis; T1D, type I diabetes; T2D, type II diabetes.}}{18}{figure.2.3}% 
\contentsline {figure}{\numberline {2.4}{\ignorespaces {\bf Accuracy of PRS prediction methods on different UK BioBank phenotypes\cite {Marquez-Luna375337}} $R^2$ Results using 5 different polygenic methods using the UK BioBank dataset and evaluating 16 different phenotypes. The $R^2$ value is compared against the maximum calculated heritability value at the top of the graphs.}}{18}{figure.2.4}% 
\contentsline {figure}{\numberline {2.5}{\ignorespaces {\bf Plaque formation and possible causes\cite {Mudher2002}} Development of Alzheimer's disease relating to the procedure via which the APP protein converts into Amyloid plaques that cause the disease. On the left are some possible environmental influences including the APOE $\epsilon 4$ gene}}{20}{figure.2.5}% 
\contentsline {figure}{\numberline {2.6}{\ignorespaces {\bf Genetic variants that contribute to Alzheimer's Disease\cite {KARCH201543}} These are some of the genes as well as the biological functions they play that increase the risk of developing Alzheimer's Disease}}{21}{figure.2.6}% 
\contentsline {figure}{\numberline {2.7}{\ignorespaces {\bf Support Vector Machine Hyper-plane classification \cite {svm1}} An example of the hyper-plane classification being done by a SVM. The data samples from different classes nearby are chosen as Support Vectors and a hyper-plane is chosen which maximizes the margin between classes.}}{24}{figure.2.7}% 
\contentsline {figure}{\numberline {2.8}{\ignorespaces {\bf Random Forest Structure\cite {rf}} The diagram shows an example of the structure a Random Forest follows, with different trees each using a subset of random features.}}{25}{figure.2.8}% 
\contentsline {figure}{\numberline {2.9}{\ignorespaces {\bf Perceptron Model\cite {percep}} The model describes a simple single-layer perceptron with the inputs on the left, followed by the weights by which to multiply them, the sum done in them and finally the activation function that leads to the output. The feedback error to guide the learning process is also shown.}}{26}{figure.2.9}% 
\contentsline {figure}{\numberline {2.10}{\ignorespaces {\bf Neural Networks, Forward-propagation and Backpropagation\cite {LeCun2015}} a) shows how MLP can make an input linearly separable by transforming the input space. b) shows the backpropagation error equation in terms of derivatives. c) gives the forward-propagation equations in a sample DNN, while d) describes the backpropagation }}{28}{figure.2.10}% 
\contentsline {figure}{\numberline {2.11}{\ignorespaces {\bf Repeated Holdout Cross-Validation with FRESA.CAD\cite {fresa}} The flow diagram depicts the RHCV procedure implemented in the FRESA.CAD benchmark used to split the input dataset for training and validation}}{32}{figure.2.11}% 
\contentsline {figure}{\numberline {2.12}{\ignorespaces {\bf FRESA.CAD Benchmark procedure\cite {fresa}} The flow diagram depicts the Benchmarking procedure across the different models and filters for comparison in each Cross-Validation iteration}}{33}{figure.2.12}% 
\contentsline {figure}{\numberline {2.13}{\ignorespaces {\bf Deep learning Architecture and results\cite {Sundaram2018}} Image a) describes the deep network architecture to predict pathogenicity depending on the given Amino Acid sequence variant, the reference and the support network results. Image b) describes the structure of the support deep networks for predicting the secondary structure and the solvent accesibility. Image c) shows the predicted pathogenicity given to mutations at specific points, as well as the reported ClinVar pathogenicity. Image d) e) and f) give the results obtain with respect to withheld variants, missense variants and classification performance}}{35}{figure.2.13}% 
\contentsline {figure}{\numberline {2.14}{\ignorespaces {\bf Overview of the prediction Architecture\cite {Zhou2017}} The diagram describes the schematic overview of the system. The Deep network receives the sequence at the genetic variant, from which it predicts chromatin profiles contrasts it between the reference and the variant and thus obtains a prediction on the functional effects.}}{36}{figure.2.14}% 
\contentsline {figure}{\numberline {2.15}{\ignorespaces {\bf Suk et al proposed method for deep learning\cite {Suk2014}}{ Method via which they create a feature representation model using deep learning by extracting patches from MRI and PET images which they process and then feed into a Deep Boltzmann Machine, the outputs of which are then classified using a SVM. }}}{38}{figure.2.15}% 
\contentsline {figure}{\numberline {2.16}{\ignorespaces {\bf Architectures from Liu et al\cite {Liu2015}}{ The architecture used to train Deep Learning architectures, first being single-modal and afterwards with the better multi-modal structure to predict the 4 classes.}}}{40}{figure.2.16}% 
\addvspace {10\p@ }
\addvspace {10\p@ }
\contentsline {figure}{\numberline {4.1}{\ignorespaces {\bf Method comparison using the Complete ADNI dataset} Analysis of the performance in terms of ROC AUC Score of the different classification methods when increasing the number of SNPs used as inputs, using 5-fold CV with the complete ADNI dataset .The SNPs used are in a descending order of statistical importance, with lower p-values as the first SNPs.}}{52}{figure.4.1}% 
\contentsline {figure}{\numberline {4.2}{\ignorespaces {\bf Method comparison using the Split ADNI dataset} Analysis of the performance in terms of ROC AUC Score of the different classification methods when increasing the number of SNPs used as inputs, training the model on the ADNI1 and ADNI GO samples and testing it in the IGAP-independent ADNI 2 Samples. }}{52}{figure.4.2}% 
\contentsline {figure}{\numberline {4.3}{\ignorespaces {\bf Impact of the subset size on the prediction} Analysis of the effect in the ROC AUC Score done by increasing the number of samples used for the 5-fold CV in the simulated dataset using the different classification methods.}}{53}{figure.4.3}% 
\contentsline {figure}{\numberline {4.4}{\ignorespaces {\bf Method Comparison with Simulated Dataset} Comparison between the ROC AUC Score obtained using the different classification methods. The X axis firstly describes an increase of the number of SNPS used for classification, and afterwards an increase in the size of the simulation dataset}}{54}{figure.4.4}% 
\contentsline {figure}{\numberline {4.5}{\ignorespaces {\bf Method comparison with 500 Individuals} Comparison of the ROC AUC Score from 5-fold CV using different classification methods while increasing the number of SNPs given a simulation dataset with 500 Individuals}}{54}{figure.4.5}% 
\contentsline {figure}{\numberline {4.6}{\ignorespaces {\bf Method comparison with 10000 Individuals} Comparison of the ROC AUC Score from 5-fold CV using different classification methods while increasing the number of SNPs given a simulation dataset with 10,000 Individuals}}{54}{figure.4.6}% 
\contentsline {figure}{\numberline {4.7}{\ignorespaces {\bf Impact of the augmentation size on the prediction} Analysis of the effect in the ROC AUC Score done by increasing the number of data-augmentation samples used for the training segment validated on the complete ADNI Dataset using the different classification methods.}}{55}{figure.4.7}% 
\contentsline {figure}{\numberline {4.8}{\ignorespaces {\bf Method Comparison with full ADNI Dataset} Comparison between the ROC AUC Score obtained using the different classification methods. The X axis firstly describes an increase of the number of SNPs used for classification, and afterwards an increase in the data-augmentation size validated on the complete ADNI dataset}}{56}{figure.4.8}% 
\contentsline {figure}{\numberline {4.9}{\ignorespaces {\bf Impact of the augmentation size in IGAP-Independent Subset} Analysis of the effect in the ROC AUC Score done by increasing the number of data-augmentation samples used for the training segment validated on the IGAP-Independent subset using the different classification methods.}}{56}{figure.4.9}% 
\contentsline {figure}{\numberline {4.10}{\ignorespaces {\bf Method Comparison with IGAP-Independent Subset} Comparison between the ROC AUC Score obtained using the different classification methods. The X axis firstly describes an increase of the number of SNPS used for classification, and afterwards an increase in the data-augmentation size validated on the IGAP-Independent subset.}}{57}{figure.4.10}% 
\contentsline {figure}{\numberline {4.11}{\ignorespaces {\bf ROC Curves for the FRESA.CAD Benchmarking Classifiers} ROC Curves obtained using BSWiMS, Random Forest, RPART and LASSO of the FRESA.CAD Benchmarking with the complete ADNI dataset for the Cross-Validation and the top 2,500 SNPs as inputs}}{58}{figure.4.11}% 
\contentsline {figure}{\numberline {4.12}{\ignorespaces {\bf ROC Curves for the FRESA.CAD Benchmarking Classifiers (Continued)} ROC Curves obtained using SVM, KNN and the Ensemble of the FRESA.CAD Benchmarking with the complete ADNI dataset for the Cross-Validation and the top 2,500 SNPs as inputs}}{58}{figure.4.12}% 
\contentsline {figure}{\numberline {4.13}{\ignorespaces {\bf Heatmap prediction comparison between FRESA.CAD Benchmark classifiers} Heatmap comparison of the prediction performance across classifiers. The Y axis describes each sample of the dataset with the real value (colour bar on the left) as well as the predicted value, while the X axis describes the different classifiers of the FRESA.CAD Benchmarking with the complete ADNI dataset for the Cross-validation and using the top 2,500 SNPs as input}}{59}{figure.4.13}% 
\contentsline {figure}{\numberline {4.14}{\ignorespaces {\bf Jaccard Index and Number of Features} Jaccard Index metric of the different classifiers between features selected as well as the number of features selected by each classifier of the FRESA.CAD Benchmarking with the complete ADNI dataset for the Cross-validation and using the top 2,500 SNPs as input }}{60}{figure.4.14}% 
\contentsline {figure}{\numberline {4.15}{\ignorespaces {\bf Balanced Error, Accuracy and AUC of the FRESA.CAD Benchmark classifiers} Comparison between the Balanced Error, Accuracy and AUC Score obtained using the different classification methods of the FRESA.CAD Benchmarking with the complete ADNI dataset for the Cross-validation and using the top 2,500 SNPs as input}}{61}{figure.4.15}% 
\contentsline {figure}{\numberline {4.16}{\ignorespaces {\bf ROC AUC, Sensitivity and Specificity of the FRESA.CAD Filter combinations} Comparison the ROC AUC, Sensitivity and Specificity Score obtained using the different combinations of classification methods plus filters of the FRESA.CAD Benchmarking with the complete ADNI dataset for the Cross-validation and using the top 2,500 SNPs as input}}{62}{figure.4.16}% 
\contentsline {figure}{\numberline {4.17}{\ignorespaces {\bf Comparison between the different classifiers and filters of the FRESA.CAD Benchmark } Radar plot analysing different metrics to evaluate the performance using different metrics as well as the CPU time between the different classifiers as well as filters of the FRESA.CAD Benchmarking with the complete ADNI dataset for the Cross-validation and using the top 2,500 SNPs as input}}{63}{figure.4.17}% 
\contentsline {figure}{\numberline {4.18}{\ignorespaces {\bf SNPs chosen more than 10\% of the time as features of the FRESA.CAD Benchmark} Heatmap of the main SNPs being chosen across all the classifiers. The Y axis are the main SNPs being selected while the X axis represents the different classifiers of the FRESA.CAD Benchmarking with the complete ADNI dataset for the Cross-validation and using the top 2,500 SNPs as input}}{64}{figure.4.18}% 
\contentsline {figure}{\numberline {4.19}{\ignorespaces {\bf Validation ROC Curves for the FRESA.CAD Benchmarking Classifiers} ROC Curves obtained using BSWiMS, Random Forest, RPART and LASSO of the FRESA.CAD Benchmarking with the validation dataset for the Cross-validation and using the top 1,000 SNPs as input}}{66}{figure.4.19}% 
\contentsline {figure}{\numberline {4.20}{\ignorespaces {\bf Validation ROC Curves for the FRESA.CAD Benchmarking Classifiers (Continued)} ROC Curves obtained using SVM, KNN and the Ensemble of the FRESA.CAD Benchmarking with the validation dataset for the Cross-validation and using the top 1,000 SNPs as inputs}}{66}{figure.4.20}% 
\contentsline {figure}{\numberline {4.21}{\ignorespaces {\bf Validation Balanced Error, Accuracy and AUC of the FRESA.CAD Benchmark classifiers} Comparison between the Balanced Error, Accuracy and AUC Score obtained using the different classification methods of the FRESA.CAD Benchmarking with the validation dataset for the Cross-validation and using the top 1,000 SNPs as input}}{67}{figure.4.21}% 
\contentsline {figure}{\numberline {4.22}{\ignorespaces {\bf Validation ROC AUC, Sensitivity and Specificity of the FRESA.CAD Filter combinations} Comparison the ROC AUC, Sensitivity and Specificity Score obtained using the different combinations of classification methods plus filters of the FRESA.CAD Benchmarking with the validation dataset for the Cross-validation and using the top 1,000 SNPs as input}}{68}{figure.4.22}% 
\contentsline {figure}{\numberline {4.23}{\ignorespaces {\bf Validation SNPs chosen more than 10\% of the time as features of the FRESA.CAD Benchmark} Heatmap of the main SNPs being chosen across all the classifiers. The Y axis are the main SNPs being selected while the X axis represents the different classifiers of the FRESA.CAD Benchmarking with the validation dataset for the Cross-validation and using the top 1,000 SNPs as input}}{69}{figure.4.23}% 
\addvspace {10\p@ }
\addvspace {10\p@ }
