% ***************************************
% ***************************************
\chapter{Conclusions and future work} \label{conclusions}
% ***************************************
% ***************************************

In this chapter, the conclusions derived from the results 
(chapter \ref{results}) are shown in section \ref{section_conclusions}. 
Additionally, future work and suggestions to extend the current investigation are shown in 
section \ref{section_future_work}. 

% ***************************************
\section{Conclusions} \label{section_conclusions}
% ***************************************



This thesis presented the hypothesis that the existence of multiple genes with low effect sizes contribute to the total risk of developing LOAD. Using a genomics-based Machine Learning and Deep Learning approach seems to be a viable alternative for Alzheimer's Disease prediction due to AD being a complex, polygenic, multifactorial disease. The methods seems to be suited to analyze the model where multiple genes spread out across the entire genome each contributing with a low risk percentage give a compound genetic risk of developing the disease. Previous research has consistently proven that Alzheimer's does have a genetic component which is complex in nature and thus using these models makes sense. The hypothesis was tested using computational experiments using the ADNI dataset where deep learning and machine learning models with multiple genetic variants as input.

The main objectives were accomplished with certain caveats: The desired score of achieving a ROC AUC score above 0.65 was accomplished both with Support Vector Machines and with the FRESA.CAD Benchmark, with the detail that these results were obtained using the whole set of the ADNI dataset. Using the simulated dataset the different algorithms were shown to perform with good performance, especially when considering an increase in the number of SNPs used as inputs coupled with an increase of the dataset size. This seems to prove the hypothesis that these Machine Learning and Deep Learning algorithms are suited for genomics problems in general. Data-augmentation was proven to be of use in one of the two subsets of data, whereas in the other did not consistently improve which begs further experiments to correctly validate its use. The performance of the models did indeed work with clinical and lossy data, as all samples had a degree of missing SNPs and were all from human patients from the ADNI Study. The dataset appears to have enough diversity to do some types of analysis and decent models were extracted from the data, but the sample size does limit the capacity of the models to learn and the statistical confidence in the results that were obtained and as such an alternate dataset is desirable. All the models appear to support the previous work done with respect to the APOE $\epsilon4$ gene, which was shown to outperform every other variant by a fair margin, but other possible variants were shown to have a correlation with the disease and could be investigated further in the future.

This thesis has shown the applicability of Machine Learning and Deep learning algorithms to predict the risk of developing Alzheimer's Disease using only the genome of an individual which would be incredibly powerful to prevent this disease at an early age. The current limitations primarily due to the complexity of the disease and the dataset limitations are also shown as avenues of improvement. This thesis is also inclined to show how Deep Learning and Machine Learning are powerful tools suited by their nature to analyze and use a multitude of genes which could be used in a variety of complex diseases similar to Alzheimer's Disease. The results tend to show that the two most important factors to ensure a good performance with these types of models to create a Polygenic Risk Scores as an alternative to statistical PRS are the use of more SNPs coupled with a larger sample size. In fact the current trend points toward the large-scale application of these methods with the ever increasing demand for individual genome sequencing and the availability of much larger datasets, both with private companies and from research groups. This shows a very promising future to fully understand the complexity of the human genome and its interactions through the use of advanced Deep Learning algorithms with the full breadth of the entire human population as learning basis, and could enable highly powerful and precise health procedures at a very early stage.

% ***************************************
\section{Future work} \label{section_future_work}
% ***************************************

There are some research questions arising from this work which can be improved upon with future work. One of the main limitations of multiple methods analyzed is that they perform better the more samples that are given to the algorithms to learn from, as well as to validate. Thus the main improvement that can be done is to increase the dataset size, having more variance and statistical power for the different methods, ensuring that datasets which are independent are used to avoid removing samples. Another challenge faced by this thesis is the complexity of the diagnosis of LOAD, using a larger dataset allows filtering out more specific samples that could reduce the uncertainty with respect to the disease diagnosis, and as more datasets are available further certainty due to the passing of the years is also generated (Such as the ADNI 3 protocol). The final problem surrounding the dataset is the class balance, given a much larger dataset or complimentary datasets from multiple sources then the balance can be adjusted more easily without losing too much of the dataset size, and the unbalance will be less pronounced the more data samples there are.

With respect to the simulation methodology the choice of having different versions or characteristics of multiple parameters could help characterize different types of complex diseases, this could be used to obtain a more accurate performance baseline from which to test the methods. The Data Augmentation procedure could also be improved upon, by using the data from a much larger study or by refining the methodology so that the data is even more closely related to the underlying statistical distribution. The choice of odds ratio and the way of handling the Linkage Disequilibrium are also factors that could be modified.

Another interesting avenue of research is the use of hand-selected markers with larger weights directly instead of allowing the learning methods to automatically select the importance of these markers. The model would then try to fit the other SNPs that have not been reported in the literature, but would ensure those that have been proved to have an impact will always be maintained.

The FRESA.CAD method can also be optimized to include the clumping procedure to have it done per Cross-validation instead of having to perform it before the algorithm to ensure that the statistical samples are in LD. This could allow the use of the complete dataset instead of the independent validation dataset. Furthermore, this could allow the usage of a direct statistical analysis instead of performing the GWAS-based filtering beforehand.

Furthermore, the candidate genes being selected as the top variants by the FRESA.CAD benchmark can also be explored to see if some marker in Linkage Disequilibrium is already reported, or if it is not to check the biological pathways that could validate the markers as being biochemically valid and not only statistical.

Finally, the LDPred-funct algorithm could be run with a much larger sample and the performance of it would be expected to considerably improve in a way as to make it worthwhile.

This thesis thus has proven to be innovative and pushed the state of the art regarding Alzheimer's Disease prediction using multiple machine learning and deep learning methods from a genomics perspective and hopes to serve as inspiration to further develop these types of models in the hope that Alzheimer's Disease can be solved for future generations.
